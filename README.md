Local RAG (Retrieval-Augmented Generation) App
This is a Local Retrieval-Augmented Generation (RAG) app that uses the Llama 3.2 3B model for generative tasks, and ChromaDB for efficient vector-based document retrieval. The app retrieves relevant documents from a local dataset, integrates metadata for context, and generates responses based on the retrieved chunks.

Features
Document Retrieval with ChromaDB: Efficient vector-based document retrieval using ChromaDB.
Generative Model (Llama 3.2 3B): Uses the Llama 3.2 3B model for generating contextually aware responses.
Metadata Support: Includes metadata with the retrieved chunks, such as document title, source, or other relevant information.
